{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lprone/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import pandas\n",
    "\n",
    "from keras.models import Sequential\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_args():\n",
    "    parser = argparse.ArgumentParser(description='Exercise 1')\n",
    "    # Here you have some examples of classifier parameters. You can add\n",
    "    # more arguments or change these if you need to.\n",
    "    parser.add_argument('--num_units', nargs='+', default=[100], type=int,\n",
    "                        help='Number of hidden units of each hidden layer.')\n",
    "    parser.add_argument('--dropout', nargs='+', default=[0.5], type=float,\n",
    "                        help='Dropout ratio for every layer.')\n",
    "    parser.add_argument('--batch_size', type=int, default=32,\n",
    "                        help='Number of instances in each batch.')\n",
    "    parser.add_argument('--experiment_name', type=str, default=None,\n",
    "                        help='Name of the experiment, used in the filename'\n",
    "                             'where the results are stored.')\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    assert len(args.num_units) == len(args.dropout)\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "def load_dataset():\n",
    "    dataset = load_files('dataset/txt_sentoken', shuffle=False)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        dataset.data, dataset.target, test_size=0.25, random_state=42)\n",
    "\n",
    "    print('Training samples {}, test_samples {}'.format(\n",
    "        len(X_train), len(X_test)))\n",
    "\n",
    "    vect = TfidfVectorizer(binary=True,min_df=4,max_df=0.99,ngram_range=(1, 2),lowercase = True,)\n",
    "    \n",
    "    # TODO 1: Apply the Tfidf vectorizer to create input matrix    \n",
    "    X_train = vect.fit_transform(X_train)\n",
    "    X_test = vect.transform(X_test)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    ## args = read_args()\n",
    "    X_train, X_test, y_train, y_test = load_dataset()\n",
    "    \n",
    "    print(\"Xtrain: \",x_train)\n",
    "    print(\"X_test: \",x_test)\n",
    "    print(\"y_train: \",y_train)\n",
    "    print(\"y_test_original\",y_test)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    batch_size = 128  # For mini-batch gradient descent\n",
    "    num_classes = 1\n",
    "    epochs = 5\n",
    "    train_examples = 60000\n",
    "    test_examples = 10000\n",
    "            \n",
    "    # normalize the input\n",
    "    x_train = x_train / 255\n",
    "    x_test = x_test / 255\n",
    "    \n",
    "    # convert class vectors to binary class matrices\n",
    "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "    y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # TODO 2: Convert the labels to categorical\n",
    "    # ...\n",
    "\n",
    "    # TODO 3: Build the Keras model\n",
    "    model = Sequential()\n",
    "    # Add all the layers\n",
    "\n",
    "    \n",
    "    # Input to hidden layer\n",
    "    model.add(Dense(512, input_shape=(input_size,)))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    # Hidden to output layer\n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    print(model.summary())\n",
    "    \n",
    "    # model.compile(...)\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.Adagrad(lr=0.001, decay=0.0001), \n",
    "                  # También podría ser el string \"Adagrad\" con los parámetros por defecto\n",
    "              metrics=['accuracy'])  # La métrica sirve para llevar algún registro además del costo\n",
    "\n",
    "\n",
    "    # TODO 4: Fit the model\n",
    "    # hitory = model.fit(batch_size=??, ...)\n",
    "    \n",
    "    model.fit(x_train, y_train, \n",
    "          batch_size=batch_size, epochs=epochs, \n",
    "          validation_data=(x_test, y_test), verbose=1);\n",
    "\n",
    "    # TODO 5: Evaluate the model, calculating the metrics.\n",
    "    # Option 1: Use the model.evaluate() method. For this, the model must be\n",
    "    # already compiled with the metrics.\n",
    "    # performance = model.evaluate(X_test, y_test)\n",
    "\n",
    "    # Option 2: Use the model.predict() method and calculate the metrics using\n",
    "    # sklearn. We recommend this, because you can store the predictions if\n",
    "    # you need more analysis later. Also, if you calculate the metrics on a\n",
    "    # notebook, then you can compare multiple classifiers.\n",
    "    # predictions = ...\n",
    "    # performance = ...\n",
    "\n",
    "    # TODO 6: Save the results.\n",
    "    # ...\n",
    "\n",
    "    # One way to store the predictions:\n",
    " #   results = pandas.DataFrame(y_test_orginal, columns=['true_label'])\n",
    " #   results.loc[:, 'predicted'] = predictions\n",
    " #   results.to_csv('predictions_{}.csv'.format(args.experiment_name),\n",
    " #                  index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples 1500, test_samples 500\n",
      "Xtrain:    (0, 17175)\t0.013559768444941327\n",
      "  (0, 44387)\t0.022988062992410657\n",
      "  (0, 1764)\t0.04484867238989352\n",
      "  (0, 1469)\t0.04484867238989352\n",
      "  (0, 22899)\t0.020861108844283768\n",
      "  (0, 44490)\t0.01543364831157002\n",
      "  (0, 3681)\t0.007349729487365338\n",
      "  (0, 32205)\t0.03781618866613296\n",
      "  (0, 22562)\t0.02686195405599507\n",
      "  (0, 21278)\t0.035883372514612294\n",
      "  (0, 28317)\t0.02948664830515774\n",
      "  (0, 113)\t0.03351365072373256\n",
      "  (0, 830)\t0.011608038969009074\n",
      "  (0, 34778)\t0.02805273243239388\n",
      "  (0, 34400)\t0.03436837642202728\n",
      "  (0, 23094)\t0.013703260911611706\n",
      "  (0, 24408)\t0.031143928932852824\n",
      "  (0, 10201)\t0.04233666606390372\n",
      "  (0, 17780)\t0.02198022593912553\n",
      "  (0, 23407)\t0.013655104519236997\n",
      "  (0, 9130)\t0.02743220660877594\n",
      "  (0, 9844)\t0.03174368217286461\n",
      "  (0, 10233)\t0.012650467668185818\n",
      "  (0, 18381)\t0.009736134678238832\n",
      "  (0, 38868)\t0.009054882917486472\n",
      "  :\t:\n",
      "  (1499, 36714)\t0.05578460339049275\n",
      "  (1499, 32797)\t0.05578460339049275\n",
      "  (1499, 13119)\t0.051873921637890695\n",
      "  (1499, 3117)\t0.05426759045507277\n",
      "  (1499, 11406)\t0.05578460339049275\n",
      "  (1499, 37140)\t0.05578460339049275\n",
      "  (1499, 26480)\t0.05298497429374845\n",
      "  (1499, 1122)\t0.050893903740908304\n",
      "  (1499, 2233)\t0.05578460339049275\n",
      "  (1499, 10976)\t0.05298497429374845\n",
      "  (1499, 839)\t0.05298497429374845\n",
      "  (1499, 11623)\t0.05578460339049275\n",
      "  (1499, 790)\t0.05578460339049275\n",
      "  (1499, 18225)\t0.05578460339049275\n",
      "  (1499, 9632)\t0.05426759045507277\n",
      "  (1499, 7074)\t0.05298497429374845\n",
      "  (1499, 3800)\t0.05426759045507277\n",
      "  (1499, 43788)\t0.05578460339049275\n",
      "  (1499, 32461)\t0.05578460339049275\n",
      "  (1499, 17557)\t0.050893903740908304\n",
      "  (1499, 15688)\t0.05578460339049275\n",
      "  (1499, 3720)\t0.05578460339049275\n",
      "  (1499, 12937)\t0.05426759045507277\n",
      "  (1499, 10726)\t0.05426759045507277\n",
      "  (1499, 37098)\t0.05578460339049275\n",
      "X_test:    (0, 45036)\t0.019268715444470046\n",
      "  (0, 44950)\t0.05481371196082617\n",
      "  (0, 44926)\t0.05770996820991519\n",
      "  (0, 44865)\t0.011244136095895333\n",
      "  (0, 44839)\t0.04825342957144496\n",
      "  (0, 44833)\t0.020921599737209928\n",
      "  (0, 44789)\t0.053664312134493075\n",
      "  (0, 44784)\t0.01876902042074685\n",
      "  (0, 44740)\t0.0494852004801122\n",
      "  (0, 44684)\t0.05614059668164082\n",
      "  (0, 44678)\t0.02600030124697785\n",
      "  (0, 44581)\t0.013391812932925549\n",
      "  (0, 44573)\t0.04535717332235594\n",
      "  (0, 44564)\t0.025786699407619823\n",
      "  (0, 44428)\t0.04146661536048226\n",
      "  (0, 44421)\t0.05770996820991519\n",
      "  (0, 44407)\t0.017156191182480445\n",
      "  (0, 44401)\t0.0494852004801122\n",
      "  (0, 44396)\t0.02946882799920409\n",
      "  (0, 44374)\t0.04420777349602284\n",
      "  (0, 44351)\t0.029404350451150488\n",
      "  (0, 44324)\t0.051743556617106196\n",
      "  (0, 44323)\t0.024791630553226276\n",
      "  (0, 44304)\t0.05265046963597957\n",
      "  (0, 44296)\t0.022999633363703777\n",
      "  :\t:\n",
      "  (499, 3591)\t0.0845231218651134\n",
      "  (499, 3588)\t0.05981708792899833\n",
      "  (499, 3415)\t0.09578799215655064\n",
      "  (499, 3286)\t0.015886976568362292\n",
      "  (499, 3246)\t0.09578799215655064\n",
      "  (499, 3245)\t0.06076992282033363\n",
      "  (499, 2939)\t0.06882699731285148\n",
      "  (499, 2892)\t0.06538145995620438\n",
      "  (499, 2740)\t0.020061176555152924\n",
      "  (499, 2442)\t0.0476786679691649\n",
      "  (499, 2302)\t0.08588484016076511\n",
      "  (499, 2270)\t0.034294831665985195\n",
      "  (499, 2268)\t0.040419853180989194\n",
      "  (499, 2209)\t0.07671452717079383\n",
      "  (499, 1661)\t0.05936348702879178\n",
      "  (499, 1504)\t0.015865699977276784\n",
      "  (499, 1368)\t0.058497329217906395\n",
      "  (499, 1354)\t0.03314530382908554\n",
      "  (499, 879)\t0.0759816881649796\n",
      "  (499, 830)\t0.02354825412866606\n",
      "  (499, 135)\t0.0752846119519899\n",
      "  (499, 116)\t0.061271280516895274\n",
      "  (499, 27)\t0.09578799215655064\n",
      "  (499, 26)\t0.06644025747125\n",
      "  (499, 1)\t0.059588487399727975\n",
      "y_train:  [1 0 0 ... 0 1 1]\n",
      "y_test_original [1 0 1 0 1 1 0 1 0 1 0 1 1 0 0 0 0 0 1 1 0 1 1 1 1 0 1 0 0 0 0 0 0 0 1 0 1\n",
      " 1 1 0 0 1 0 0 1 0 0 0 0 1 1 0 1 0 0 1 1 1 1 0 1 0 1 1 1 1 0 1 0 1 1 0 1 1\n",
      " 0 0 1 0 0 1 0 0 1 1 1 1 1 0 0 1 1 1 0 0 1 1 0 1 1 1 0 0 0 1 0 0 0 0 0 0 0\n",
      " 1 1 1 0 0 1 0 0 1 1 1 1 0 0 1 0 0 1 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 1 0 0 1\n",
      " 0 0 1 0 0 1 0 0 0 1 0 1 0 0 0 1 1 1 1 1 0 1 1 0 1 1 0 1 0 1 0 1 1 0 1 1 0\n",
      " 0 1 1 1 1 0 0 1 0 0 0 1 0 0 1 1 0 0 0 0 0 1 1 1 0 1 0 0 0 0 1 1 0 0 1 0 0\n",
      " 0 1 1 1 0 0 1 0 1 0 1 1 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 1 1 0 1 0 1 1 0 0 1\n",
      " 1 0 1 0 1 1 1 0 0 0 1 1 1 0 1 1 1 0 0 1 0 1 1 0 1 1 0 0 1 0 0 1 1 1 1 0 0\n",
      " 0 1 1 0 0 0 1 1 0 1 1 1 0 0 1 1 1 0 1 0 1 1 1 1 0 1 0 0 0 0 1 0 1 0 0 0 1\n",
      " 0 0 1 0 0 1 1 1 0 1 0 0 1 0 1 1 0 0 0 1 1 0 0 1 1 1 1 0 0 0 0 0 0 1 0 1 0\n",
      " 1 1 0 1 1 1 0 1 1 1 1 0 0 1 1 0 0 1 0 1 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1\n",
      " 0 1 1 0 0 1 0 0 1 0 0 0 1 0 0 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 0 0 1 0 0 1 0\n",
      " 1 0 0 1 0 1 0 1 0 1 1 1 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 1 0 0 0 0 1 0 1 0 0 0 1 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
