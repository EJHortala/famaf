---
title: "Trabajo Práctico 2"
author: "Prone, Lucas y Bergamasco, Julieta"
date: "May 17, 2018"
output: html_notebook
---

#Elección del Dataset

Para este trabajo práctico elegimos el siguiente dataset, obtenido de la base de datos del World Bank:

```{r}
WBData <- read.csv(file="Dataset\\WDI_csv\\WDIData.csv", header=TRUE, sep=",", quote = "\"")

head(WBData, n = 1)

names(WBData)[1]<-paste("Country.Name")
```

Exsiten muchos indicadores, de los cuales elegimos los siguientes 12 para representar el espacio de features:

```{r}
condition <- (WBData$Indicator.Code == "EG.CFT.ACCS.ZS" | WBData$Indicator.Code == "EG.ELC.ACCS.ZS" | WBData$Indicator.Code == "EG.ELC.ACCS.RU.ZS" | WBData$Indicator.Code == "EG.ELC.ACCS.UR.ZS" | WBData$Indicator.Code == "per_si_allsi.adq_pop_tot" | WBData$Indicator.Code == "per_allsp.adq_pop_tot" | WBData$Indicator.Code == "per_sa_allsa.adq_pop_tot" | WBData$Indicator.Code == "per_lm_alllm.adq_pop_tot" | WBData$Indicator.Code == "EG.USE.COMM.CL.ZS" | WBData$Indicator.Code == "SH.XPD.GHED.PC.CD" | WBData$Indicator.Code == "SI.POV.GINI" | WBData$Indicator.Code == "EG.FEC.RNEW.ZS")


filtered_WBData <- subset(WBData, condition)

head(filtered_WBData)
```

#Elección del Datataset

Por otro lado, la categoría que queremos predecir la obtenemos del siguiente Dataset, que clasifica a los distintos países según sus niveles de ingreso:

```{r}
WBDataCountry <- read.csv(file="c:\\Users\\Julieta\\Diplomatura FaMAF\\2- Exploración y Curación de Datos\\Dataset\\WDI_csv\\WDICountry.csv", header=TRUE, sep=",", quote = "\"")

head(WBDataCountry)
```

#Exploramos el Dataset

```{r echo=TRUE}
names(filtered_WBData)
str(filtered_WBData)
dim(filtered_WBData)
```

```{r echo=TRUE}
names(WBDataCountry)
str(WBDataCountry)
dim(WBDataCountry)

unique(WBDataCountry$Income.Group, incomparables = FALSE)

table(WBDataCountry$Income.Group)
```

```{r}
names(WBDataCountry)[1]
colnames(WBDataCountry)[which(names(WBDataCountry) == "ï..Country.Code")] <- "Country.Code"
names(WBDataCountry)[1]
```

Seleccionamos la clasificación que nos interesa del país:

```{r}
myvars <- c("Country.Code", "Income.Group")
WBDataCountryNw <- WBDataCountry[myvars]
WBDataCountryNw

filtered_WBDataCountryNw <- WBDataCountryNw[!(!is.na(WBDataCountryNw$Income.Group) & WBDataCountryNw$Income.Group==""), ]
filtered_WBDataCountryNw
```

Volviendo al dataset con los features,

```{r}
install.packages("reshape", type="source")
install.packages("reshape2", type="source")
library(reshape)
library(reshape2)

# Transposicion de datos (features a columnas)
temp <- filtered_WBData[, (colnames(filtered_WBData) %in% c("Country.Name","Country.Code","Indicator.Name","Indicator.Code","X2016"))]

head(temp,n = 5)
final_data <- cast(temp, Country.Name ~ Indicator.Code)
head(final_data,n = 5)
str(final_data)

#Random
head(final_data[sample(nrow(final_data)),],n=5)

```

```{r echo=TRUE}
summary(data)
```

Hacemos un Unpivot a los años:

```{r}
library(reshape)
temp1 <- filtered_WBData[, (colnames(filtered_WBData) %in% c("Country.Code","Indicator.Code","X2000","X2016"))]

head(temp1)
WBDataUnpiv <- melt(temp1)
head(WBDataUnpiv)
names(WBDataUnpiv)[3]<-paste("Year")
head(WBDataUnpiv)

WBDataUnpiv$Year <- gsub('X', '', WBDataUnpiv$Year)
head(WBDataUnpiv)

#paste(WBDataUnpiv$Indicator.Code, WBDataUnpiv$Year, sep=".")
#WBDataUnpiv$Indicator.Code + '.' +WBDataUnpiv$Year
WBDataUnpiv$Indicator.Code.Year = paste(WBDataUnpiv$Indicator.Code, WBDataUnpiv$Year, sep=".")
head(WBDataUnpiv)


temp2 <- WBDataUnpiv[, c("Country.Code","Indicator.Code.Year","value")]

head(temp2)
#filtered_WBDataUnpiv <- na.omit(WBDataUnpiv)
filtered_WBDataUnpiv <- temp2
head(filtered_WBDataUnpiv)
  
```

```{r}
final_database <- merge(x = filtered_WBDataUnpiv, filtered_WBDataCountryNw, by = "Country.Code", all.x = TRUE)

head(final_database,n = 2)

final_database <- final_database[, c("Income.Group","Country.Code","Indicator.Code.Year","value")]
head(final_database,n = 2)

final_database <- cast(final_database, Country.Code ~ Indicator.Code.Year)
head(final_DB,n = 5)

final_DB <- merge(x = final_database, filtered_WBDataCountryNw, by = "Country.Code", all.x = TRUE)
names(final_DB)

head(final_DB,n = 2)

```


```{r}
table(final_DB$Income.Group)
summary(final_DB)
```

Luego de ver el resumen para los indicadores y años seleccionados, nos encontramos con que existen muchos datos faltantes, por lo que descartamos aquellos indicadores que no podremos utilizar como características para ubicar los datos en el espacio de features:

```{r}
names(final_DB)
final_DB_ord <- final_DB[c(26,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25)]
names(final_DB_ord)

final_DB_filtered <- final_DB_ord[c(1,2,3,4,5,6,7,8,9,10,11)]
summary(final_DB_filtered)

md.pattern(final_DB_filtered)
final_DB_filtered_na <- na.omit(final_DB_filtered)
md.pattern(final_DB_filtered_na)
summary(final_DB_filtered_na)

table(final_DB_filtered_na$Country.Code)

names(final_DB_filtered_na)
str(final_DB_filtered_na)
```

```{r echo=TRUE}
plot(final_DB_filtered_na[,6:8], col= final_DB_filtered_na[, 1])
```



```{r}
#Random
database_rdm <- final_DB_filtered_na[sample(nrow(final_DB_filtered_na)),]
head(database_rdm,n=5)
```




### ejemplo de K-means:

```{r echo=TRUE}
set.seed(20)
DBCluster <- kmeans(database_rdm[, 3:11], 3, nstart = 20)
DBCluster
```

***
### ejemplo de K-means:

```{r}
table(DBCluster$cluster, database_rdm$Income.Group)
```

```{r}
library(ggplot2)
DBCluster$cluster <- as.factor(DBCluster$cluster)
ggplot(database_rdm, aes(EG.ELC.ACCS.UR.ZS.2016, EG.ELC.ACCS.RU.ZS.2016, color = DBCluster$cluster)) + geom_point()

```



```{r}
DBCluster_k4 <- kmeans(database_rdm[, 3:11], 4, nstart = 20)
DBCluster_k4
table(DBCluster_k4$cluster, database_rdm$Income.Group)
DBCluster_k4$cluster <- as.factor(DBCluster_k4$cluster)
library(ggplot2)
ggplot(database_rdm, aes(EG.ELC.ACCS.UR.ZS.2016, EG.ELC.ACCS.RU.ZS.2016, color = DBCluster_k4$cluster)) + geom_point() + scale_color_gradientn(colours = rainbow(5)) #scale_color_brewer(palette="Set2")
```

















Necesitamos crear una funcion normalizacion en R. En este caso utilizaremos la función scale, para normalizar los datos en base a la media y la desvaición estandar de cada indicador:

```{r echo=TRUE}
normalize_scale <- function(x) {
  return (scale(x))
}

data_norm <- as.data.frame(lapply(final_DB_filtered_na[3:11], normalize_scale))
summary(data_norm)
```

```{r}
plot(data_norm[,1:4], col = iris$Species, pch = 18, main = "Fisher's Iris Dataset")



```







### Entrenando un clasificador:

Notese que dichos conjuntos de datos deben ser representativos del conjunto de datos, i.e. **metodos de muestreo aleatorios**!

Antes tenemos que desordenar el dataset.
iris[sample(1:nrow(iris), 40), "Sepal.Length"]?
```{r echo=TRUE}
data_train <- data_n[1:469, ]
data_test  <- data_n[470:569, ] 
```

Excluimos la variable objetivo (Benigno/Maligno), pero necesitamos guardar estos factores en vectores!

```{r echo=TRUE}
data_train_labels <- data[1:469, 1]
data_test_labels  <- data[470:569, 1]
```


### Evaluando la performance del modelo.


```{r echo=TRUE}
library(class)
data_test_pred <- knn(train=data_train, test=data_test, cl=data_train_labels, k=21)
```

El siguiente paso en el proceso es evaluar como las clases predichas en data_test_pred
se condicen con los valores verdaderos en el vector data_test_labels.

```{r echo=TRUE}
library(gmodels)
CrossTable(x=data_test_labels, y=data_test_pred, prop.chisq = FALSE)
```
